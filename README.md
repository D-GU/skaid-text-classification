# Структура проекта

* `classify.py` – Основной скрипт для запуска классификации. Принимает на вход путь к PDF-файлу, обрабатывает документ через парсер и препроцессор, загружает обученную модель и выводит предсказанную категорию в консоль.
* `src/document_handler/` – Пакет для обработки документов:
  * `parser.py` – Парсер PDF-документов, использует библиотеку `PyMuPDF` для извлечения всего текста из PDF-файла. Если файл не найден или в нём отсутствует текстовый слой, генерирует исключение.
  * `text_preprocessor.py` – Предобработчик текста. Очищает сырой текст (удаляет URL-ссылки, спецсимволы, приводит к нижнему регистру), выполняет токенизацию слов с помощью NLTK и удаляет стоп-слова (английские стоп-слова из NLTK).
  * `vectorizer.py` – Векторизатор токенов. Преобразует список токенов в числовой вектор фиксированной длины с использованием TF-IDF (через `sklearn.feature_extraction.text.TfidfVectorizer`). На этапе обучения строит словарь терминов по всему корпусу, а при классификации превращает входной текст в вектор признаков той же размерности.
* `src/model/` – Пакет, относящийся к модели и ее обучению:
  * `model.py` – Определение нейросети `TextClassifier` на основе `PyTorch` (Для цикла обучения используется `PyTorch Lightning`). Это простая полносвязная нейронная сеть: входной слой размером ~117 тысяч признаков (Размер словаря TF-IDF), скрытый слой на 512 нейронов с `ReLU` и `Dropout`, выходной слой из 20 нейронов (по числу классов). Также определены метрики качества (`Accuracy`, `Precision`, `Recall`) и функция потерь `CrossEntropyLoss` для обучения.
  * `model_cfg.py` – Конфигурация модели и обучения в виде датакласса `ModelCFG`. Содержит гиперпараметры: устройство для вычислений (cpu/gpu), размер входного и скрытого слоёв, коэффициент dropout, скорость обучения, размер батча, число эпох, количество классов (20) и т.д. Эти параметры используются как при обучении модели, так и при её загрузке для инференса.
  * `dataset.py` – Класс NewsgroupsDataset для подготовки данных обучения/тестирования. При инициализации автоматически загружает датасет 20 Newsgroups из sklearn.datasets, разбивает на обучающую или тестовую выборку, очищает каждый текст (через `TextPreprocessor`) и векторизует его (через `Vectorizer`). Для обучающей выборки строится словарь TF-IDF, который затем применяется и к тестовым данным. Этот класс используется внутри `TextClassifier` для получения `DataLoader`-ов.
  * `train.py` – Скрипт для обучения модели. Инициализирует модель TextClassifier и запускает обучение через `pytorch_lightning.Trainer` (с заданными в конфигурации числом эпох, устройством и пр.). По окончании обучения выводит результаты на тестовом наборе. Примечание: После обучения модель можно сохранить в файл.
  * `categories.json` – JSON-файл со списком из 20 категорий (тематик) в том порядке, в котором модель выдает предсказание. Используется скриптом классификации для преобразования индекса предсказанного класса в понятное название категории.
* `2306.17358v3.pdf` – Пример PDF-файл (научная статья), включённый для демонстрации. Вы можете использовать его для тестирования работы классификатора или попробовать собственные PDF-документы.
---

# Установка

Перед использованием убедитесь, что у вас установлена соответствующая среда Python.

1. Клонирование репозитория: Склонируйте проект на свой компьютер или загрузите исходный код в виде архива и распакуйте:


    `git clone <URL_репозитория>`

    `cd skaid`   # перейдите в папку проекта
2. Создание окружения (рекомендуется): Рекомендуется использовать виртуальное окружение для установки зависимостей, чтобы избежать конфликтов. Например, с помощью `venv`:


    `python3 -m venv venv`

    `source venv/bin/activate`
3. Установка зависимостей:


  `pip3 install -r requirements.txt`
  
Примечание: Библиотека `PyMuPDF` устанавливает модуль для работы с PDF (импортируется в коде как `pymupdf`). Библиотека `NLTK` при первом запуске скачает нужные ресурсы (стоп-слова, токенизатор и WordNet) автоматически. Убедитесь, что при первом запуске у вас есть доступ в интернет для загрузки датасета `20Newsgroups` и ресурсов `NLTK`.
4. Подготовка модели: Убедитесь, что в директории проекта присутствует файл с обученными весами модели `document_classifier.pth`. Этот файл необходим для работы скрипта классификации (загружается внутри `classify.py`). Если у вас нет готового файла с весами, см. раздел Обучение модели о том, как обучить модель и создать этот файл.
---

# Запуск классификации

После установки зависимостей и подготовки модели вы можете запустить классификацию PDF-документа. Команда для запуска скрипта:

`python3 classify.py <filepath>`

Где `<filepath>` – это путь до PDF-документа, который вы хотите проанализировать. Скрипт `classify.py` последовательно выполнит следующие шаги:

1. Парсинг PDF: исходный PDF-файл будет открыт и из него извлечён весь текст с помощью `Parser()`. Если файл не найден либо не содержит извлекаемого текста (например, PDF состоит только из сканов-изображений), программа выведет сообщение об ошибке.
2. Предобработка текста: полученный сырой текст будет очищен от лишних символов, приведён к нижнему регистру, токенизирован на слова и очищен от стоп-слов через `TextPreprocessor()`.
3. Векторизация: список полученных токенов будет преобразован в вектор признаков фиксированной длины с помощью TF-IDF векторизатора. Векторизация использует словарь, сформированный на этапе обучения модели, чтобы соответствовать ожидаемым входам нейросети.
4. Классификация моделью: предобработанный текстовый вектор подаётся в нейронную сеть `TextClassifier`. Модель вычисляет логиты для 20 классов и выбирает самый вероятный класс.
5. Результат: индекс предсказанного класса преобразуется в название категории (согласно списку в `categories.json`), и программа выводит результат в консоль.

Предсказанная категория отображается в формате: Предсказанная категория: `<имя категории>`.

---

# Примеры использования

Ниже приведены примеры запуска классификатора из командной строки и ожидаемого вывода:

  * Классификация примера, входящего в комплект проекта (файл научной статьи):

    `$ python3 classify.py 2306.17358v3.pdf`

    `Предсказанная категория: comp.graphics`
  
  _(В данном случае документ о генерации теней в изображениях был отнесён моделью к категории comp.graphics, связанной с компьютерной графикой.)_  

---

# Заключение

Данный проект демонстрирует полный цикл решения задачи классификации текста: от обработки PDF-документа до выдачи предсказанной категории с помощью простой нейронной сети. Вы можете использовать этот инструмент для автоматической классификации документов по темам.